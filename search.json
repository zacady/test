[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis for the Social Sciences",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Variables\nWe have seen that well-being can usefully be considered as a variable to convey that it is not identical for everyone and at all times. The same is true for things like personality, gender, income, or the type of neighbourhood one lives in. You might notice that, by calling all these information “variables”, we are lumping quite different things together: income, for instance, is a quantity - it can meaningfully be represented by a number - while gender is not. Distinctions of this sort are important, and we will discuss them in due course. For now, suffice it to say that",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#variables",
    "href": "intro.html#variables",
    "title": "1  Introduction",
    "section": "",
    "text": "A variable is a quantity or a quality that varies.\n\n\n1.1.1 Theoretical and operational variables\nBut what do we mean exactly when we use the word “well-being”? Is it the same as happiness? Or satisfaction with one’s life? One of your tasks as a researcher will be to define your phenomenon of interest as clearly possible. We call such clearly defined concept a theoretical variable (or a theoretical construct).\nFor instance, having thoroughly reviewed the existing knowledge on the topic, you might conclude that the notion of well-being can be defined as a special case of the sentiment of satisfaction. This sentiment of satisfaction, you add, is not related to any particular aspect of the person’s life, but rather about all aspects considered together. Hence, you decide to define well-being as an individual’s degree of satisfaction with their life considered in all its aspects. This would be your theoretical variable.\nNote that defining a theoretical variable (well-being, in this case) has less do to with laying out what well-being ‘truly is’ than with being clear about what you mean when using the term.1 After all, definitions of terms are conventional: a term can be said to have a “true meaning” only in the sense of a meaning that is agreed upon by some set of people. What matters the most when defining your theoretical variable is to be clear – i.e., to leave as little ambiguity as possible regarding what it does and does not refer to in the real world. But this does not mean that you can just ignore how you theoretical variable is usually defined by other scientists, or even among the general public. Conventions in terminology facilitate smooth communication, and departing from them can result in misunderstandings. Claiming to study “well-being” while actually defining that term as an individual’s preference for cats over dogs would be unreasonably confusing, no matter how clear the definition. In sum, you should depart from conventional definitions only if you have good reasons to do so, such as when it helps distinguishing your theoretical variable better from closely related concepts.\n\nA theoretical variable is the concept of interest defined in abstract and general terms.\n\nHaving clearly defined your theoretical variable is not enough, however, because such a variable cannot be directly observed the real world. Think about well-being: however clearly you define it, you cannot simply observe a person and self-evidently know their well-being. You will need to find a concrete procedure to extract the information corresponding to your theoretical concept in the real world. Such procedure is what we call measurement. And the information obtained through measurement is the operational variable.\nSince in our example we defined our theoretical variable in subjective terms – through the feeling of satisfaction – you could reason that the best way to extract the corresponding information would be to directly ask people. You might thus devise a questionnaire including a question similar to the following: thinking of your life as whole, how satisfied would you say you are on a scale ranging from 1 (not satisfied at all) to 10 (completely satisfied)?\nIdeally, you should select a measurement procedure with the aim that the resulting operational variable should faithfully and reliably reflect the theoretical variable. Consider the measure of well-being proposed in the previous paragraph, for instance. If an individual happen to be in a bad mood while answering the question, the negative aspects of her life might come to her attention more readily than the positive ones, leading her to rate her own well-being lower than she would have earlier or later that day. If the aim is to capture satisfaction with one’s life as a whole, this measurement wouldn’t be very reliable because its outcome would change with every mood swing. A strategy to limit this problem would be to present participants with a series of questions, each focusing on a specific aspect of their life (e.g., finances, physical health, friendships, etc.) and aggregate all answers into a composite score. This way, participants would be prompted to pay attention to the different facets of their life instead of being guided by what their transient state of mind brings to their attention.\n\nAn operational variable is the information, obtained through a concrete measurement procedure, used to represent real-world realizations of the theoretical variable.\n\nThis example illustrates that devising a measurement procedure that yields a sound operational variable can be a tricky endeavour. Researchers have developed a set of tools that can help us in this task. We will discuss some of these tools later. Examples of work defining well-being as a theoretical variable and proposing a way to measure it can be found in Diener et al (2010) and Weziak-Bialowolska et al (2021).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#hypotheses",
    "href": "intro.html#hypotheses",
    "title": "1  Introduction",
    "section": "1.2 Hypotheses",
    "text": "1.2 Hypotheses\nRemember what thinking in terms of variables taught us: to explain well-being, you would need to find explanations that account for its variability in the real world. And we have seen that we could think of many possible explanations. Let us consider one of them, as an example: well-being is affected by income. We will call this statement a hypothesis.\nA first thing to note about this statement is that it indicates that well-being is explained by another variable: income. Just like well-being, income is not the same for everyone, and can vary from time to time for a given individual. Hence, income is also a variable. And our hypothesis states that this variable explains well-being.\nSecond, one thing that makes the sentence well-being is affected by income a valid hypothesis is that it is a statement. On the contrary, the sentence is well-being affected by income? is a question rather than a statement and, hence, doesn’t qualify as a hypothesis.\nA third notable feature is that we are stating something that we don’t actually know. Maybe income does affect well-being, maybe it doesn’t. We might have a strong belief about it, but it is crucial to always consider that our belief might turn out to be false. Indeed, the very purpose of a hypothesis is to formulate a factual statement that can be confronted with observations in the real world. Therefore, a statement qualifies as a hypothesis only if it is in principle possible to prove it wrong by observation. That is, we should be able to think of a situation in which what we observe will show us that the hypothesis is false, if it is indeed false. We say that a hypothesis must be falsifiable.\nTo make this last point clearer, consider the statement well-being is undermined by memories of childhood trauma even if they have been suppressed. Try to think of an observation that would prove this statement wrong. For instance, you could ask a large number of individuals to recall any childhood trauma and then compare the well-being of those who recall traumatic experiences to the well-being of those who don’t. But even if well-being turns to be exactly the same in both groups, the statement implies that those who don’t recall any trauma could have in fact suppressed such memories. Whatever observation we make, it seems that we can always “save” the statement from being proven wrong by invoking the notion that memories can be suppressed and, hence, can remain undetected. This statement thus appears unfalsifiable. It is not a valid hypothesis.\n\nA hypothesis is a statement, either about a variable or (more tyically) about the relationship between variables, which is in principle falsifiable through observation.\n\nNote how the definition above leaves room for hypotheses that concern only one variable. For instance, the statement “Among humans, it is more frequent to be born a female than a male” is a valid hypothesis although it refers to one variable only: sex. It is a hypothesis about the distribution of one variable.\n\n1.2.1 Dependent and independent variables\nWhen we hypothesize that two variables are related, we usually specify the relationship a bit further. If I say Well-being is affected by income, well-being and income are both variables, but one (well-being) is the thing we are trying to explain whereas the other (income) is the proposed explanation. We call them dependent variable and independent variable, respectively (see Figure 1.1).\n\nIn a hypothesis, the dependent variable is the variable that we are trying to explain whereas the independent variable is the variable that we hypothesize to explain the dependent variable.\n\n\n\n\n\n\n\n\n\nG\n\n\n\nIV\n\nIndependent\nvariable\n\n\n\nDV\n\nDependent\nvariable\n\n\n\nIV-&gt;DV\n\n\n\n\n\n\n\n\nFigure 1.1: Typical structure of a hypothesis\n\n\n\n\n\nNote that this not the only terminology used by scientists. A dependent variable is also called an outcome or a response variable. And an independent variable is also referred to as a predictor or an explanatory variable.\nOne reason often invoked for preferring alternative terms is that the terminology of dependent and independent variable is usually understood as implying a causal relationship. And causality is a very difficult thing to test. Thus, when researchers do not have the means of testing the existence a causal relationship, they often opt for a terminology that does not evoke causality in the first place.\n\n\n1.2.2 Theoretical and operational hypotheses\nRecall our distinction that we made Section 1.1.1 between theoretical and operational variables. Since hypotheses talk about variables, it is natural that we should make a similar distinction here.\n\nA theoretical hypothesis is a general statement about the relationship between theoretical variables.\nAn operational hypothesis is a statement about the relationship between operational variables in a clearly specified study setting.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#modelling",
    "href": "intro.html#modelling",
    "title": "1  Introduction",
    "section": "1.3 Modelling",
    "text": "1.3 Modelling\nAs social scientists, we should always remember that the phenomena we wish to explain are extremely complex. This means that we should abandon the illusion that we could explain them perfectly. Rather, we will rely on simplified descriptions of reality which capture relevant and useful aspects of it instead of grasping it in all complexity. We call such a simplification of reality a model.\n\n1.3.1 Why do we need models?\nTo understand why, let us consider once again hypotheses that could explain why well-being is not identical for everyone and at all times. It might be because well-being changes depending on variables like income, personality, physical and mental health, gender, life events, relationships, diet, sleep quality, and so on. The important thing to realize is that this list could go on. And on. Identifying all the variables that could potentially explain well-being is so difficult that we might as well consider it impossible in practice.\nBut even if we could know all the variables that affect well-being (which we can’t), grasping how exactly these variables influence well-being is way beyond what our minds can handle. Take the hypothesis that income fosters well-being: what amount of money exactly makes a difference? And does more income always lead to more well-being or is there an amount beyond which earning more doesn’t make any difference? Are there personalities or cultures for which income matters more for well-being? Such questions also could go on.\nAnd finally, even if we knew all the relevant variables and understood how exactly they shape well-being (which, again, we can’t), it would be impossible to measure them all and to do so with perfect accuracy. Measuring things takes time and resources, and measuring all the variables that might be relevant would require a gigantic amount of both. Moreover, some variables are very difficult to measure accurately. Think of any variable that is inherently subjective: well-being, personality, beliefs, emotions, and so on.\n\n\nThree reasons for humility\n\n\nIt is virtually impossible to identify all the variables that explain a given phenomenon.\nIt is virtually impossible to grasp how these variables influence our phenomenon of interest.\nIt is virtually impossible to measure all the variables that explain a given phenomenon and to do so with perfect accuracy.\n\n\n\n\n1.3.2 What is a model?\nThus, our attempts at explaining a phenomenon will necessarily result in a simplification of reality. This might sound disappointing. But simplifying reality can actually be a very useful thing to do.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Example of model (the world map) of a complex reality (the earth’s surface)\n\n\n\n\nConsider for instance a simple map of the world, like the one shown in Figure 1.2. In a sense, we can say that such a map describes the surface of our planet. Of course, it does so in a very incomplete and inaccurate way: lots of complicated stuff are constantly happening on earth which are not depicted on this map, like weather-related processes happening in the atmosphere, the organisation and movement of tectonic plates, water streams circulating in the oceans or the billions of living creatures populating the surface. But it is precisely because such a map is an incomplete description that it is useful to us. By extracting a few features from a highly complex reality, it makes it manageable for our minds to grasp relevant information which, otherwise, would be drown in an ocean of complexity. Thanks to the simplicity of the map, we can clearly identify the parts of the earth’s surface that are not covered by water, how this landmass was partitioned into countries by humans, and their geographic positions relative to the poles and the equator. The map is thus a simplification of the reality it aims to describe – i.e., the earth’s surface. But it is an informative simplification. We can say that the map is a model of the earth’s surface.\n\nA model is a simplified representation, which aims at describing relevant aspects of reality while ignoring others.\n\n\n\n1.3.3 Data analysis as the art of modelling\nNow that we have established an intuitive understanding of what a model is, we are ready for the most important insight you should take away from this chapter: Data analysis is the art of building and interpreting statistical models. What this means, and what we will see throughout this book, is that data analysis always comes down to applying the fundamental principle described in the equation in Box1.1 . Let us unpack what this equation means.\n\n\n\nThe fundamental principle of data analysis  \\[\nData = Model + Error\n\\]\n\n\nFigure 1.3\n\n\n\nIn the context of a scientific study, the phenomenon we wish to explain will be represented by a set of data. Our task is to build, based on the information at our disposal, an explanatory model that best accounts for these data.\nSuppose you hypothesize that well-being depends on income. You ask 100 people their income (in dollars) and measure their well-being on a scale ranging from 1 to 10. The scores of well-being would be the data we are trying to explain, and the income is the information we can use to build a model. Applying our general equation in Box1.1 to this imaginary data, we could obtain something like this:\n\\[\nWellbeing_i=-5.261+0.005 \\times Income_i+Error_i\n\\] Or using more conventional notations:\n\\[\nY_i=-5.261+0.005X_i+e_i\n\\tag{1.1}\\]\nWhat the numbers in Equation 1.1 mean, and how to obtain them, is not important now. We will cover that in due course. What matters at this point is that you get a feel of how the elements making up the fundamental equation shown in Box1.1 might look like in a concrete case.\nNow, let us use this concrete example to understand what our fundamental principle means. In Equation 1.1, the symbol \\(Y_i\\) represents Well-being, our dependent variable. This is the thing we are trying to explain, the Data. (The subscript \\(i\\) is there to remind us that \\(Y\\), Well-being, can take different values. Its exact meaning will become clear later).\nThe Model is given by the expression \\(-5.261+0.005X_i\\), where \\(X_i\\) represents Income, our independent variable. A statistical model is a mathematical expression, usually very simple, that generates guesses about what the data are. We say that the model makes predictions about the data. You can think of it a little prediction machine. And we can give it information to base its predictions on. In this case, for instance, we used Income, \\(X_i\\), as an information for the model to use in generating predictions.\n\nA statistical model is a simple mathematical expression that generates guesses (predictions) about what each data point is.\nA model prediction is what a data point should be according to the model.\n\nBut remember that our model will, as a rule, be a simplification of reality; it will not completely explain it. In practice, this means that there will be some discrepancies between our model predictions and the actual data. We say that our model will make errors. These errors are represented by the symbol \\(e_i\\) in Equation 1.1.\n\nAn error is the distance between a model prediction and the corresponding data point.\n\nMathematically, an Error has a very straightforward definition. Given the general equation\n\\[\nData = Model + Error\n\\]\nWe can isolate the Error as follows\n\\[\nData - Model = Error\n\\]\nOr\n\\[\nError = Data - Model\n\\] Using conventional notations, we express exactly the same equation as\n\\[\ne_i = Y_i - \\hat{Y}_i\n\\] Where \\(\\hat{Y}_i\\) represents the predictions made by our model.\n\n\n1.3.4 Two criteria that define a good model\nA statistical model, we saw, is just a mathematical expression that generates predictions about what the data are. Based on this definition alone, we have infinitely many options as to what particular model we choose for a given set of data. So how do we choose? There are two criteria that will guide us in our choice.\nThe first criterion is the most obvious: our model should make the least possible amount of errors in its predictions. At the end of the day, our purpose is to explain the phenomenon represented by the data. The more our model predictions differ from the data, the further it gets from achieving this purpose. In other words, the less errors our model makes, the better it explains the data.\nThe second criterion is more subtle. To understand it, remember why we use models in the first place. We know that the data we are trying to explain represent a complex reality generated by a vast amount of intricate causal processes. The point of using a model is to simplify this complexity by extracting relevant information that is useful to us (see Section 1.3.2). In other words, the very usefulness of a model lies in its simplicity. Thus, our model should be as simple as possible.\n\n\n\n\nTwo virtues of a good model\n\n\n\nAccuracy: A good model should make as little prediction error as possible.\n\n\nSimplicity: A good model should be as simple as possible.\n\n\n\n\nFigure 1.5\n\n\n\n\n\n\n\nDiener, E., Wirtz, D., Tov, W., Kim-Prieto, C., Choi, D., Oishi, S., & Biswas-Diener, R. (2010). New Well-being Measures: Short Scales to Assess Flourishing and Positive and Negative Feelings. Social Indicators Research, 97(2), 143–156. https://doi.org/10.1007/s11205-009-9493-y\n\n\nPopper, K. R. (2020). The Open Society and Its Enemies. Princeton University Press.\n\n\nWeziak-Bialowolska, D., Bialowolski, P., Lee, M. T., Chen, Y., VanderWeele, T. J., & McNeely, E. (2021). Psychometric properties of flourishing scales from a comprehensive well-being assessment. Frontiers in Psychology, 12. https://doi.org/10.3389/fpsyg.2021.652209",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "The philosopher of science Karl Popper (Popper, 2020) has criticized the view – which he associates with Aristotle – that concepts have a true essence that our definition should reflect. Rather, Popper argues, scientific concepts are just labels that we put on real-world processes. Thus, it does not really matter which label we use to refer to a given process, as long as we clearly define what our label refers to and use our terminology consistently. Popper refers to his view as “methodological nominalism” as opposed to Aristotle’s “methodological essentialism”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Logic.html",
    "href": "Logic.html",
    "title": "2  Elements of logic",
    "section": "",
    "text": "2.1 Arguments\nArguments are made up of basic statements called propositions.\nTwo types of propositions form an argument: the premises and the conclusion.\nThe premises are propositions forming the basis on which the argument rests. The conclusion is the proposition",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Elements of logic</span>"
    ]
  },
  {
    "objectID": "Logic.html#arguments",
    "href": "Logic.html#arguments",
    "title": "2  Elements of logic",
    "section": "",
    "text": "Propositions are basic statements that are either true or false.\n\n\n\nThe premises are the reasons invoked to justify the conclusion.\nThe conclusion is the proposition inferred based on the premises.\n\n\n\n(P1): This orange is good.\nTherefore: All oranges in the box are good.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Elements of logic</span>"
    ]
  },
  {
    "objectID": "Logic.html#deductive-logic",
    "href": "Logic.html#deductive-logic",
    "title": "2  Elements of logic",
    "section": "2.2 Deductive logic",
    "text": "2.2 Deductive logic\nDeductive logic is concerned with identifying the form of arguments whereby the conclusion can be safely derived from the premises.\n\n2.2.1 Validity\nConsider Argument (1), for instance:\n\nArgument (1)\nPremise 1: The cat is either dead or alive.\nPremise 2: The cat is not dead.\nConclusion: The cat is alive.\n\nIf Premise 1 and 2 are true, there is absolutely no way that the conclusion is not true. Logicians have a specific term to refer to this property: they say that such an argument is valid.\n\nA deductive argument is valid if and only if the truth of all the premises necessarily implies the truth of the conclusion. Otherwise, it is invalid.\n\nIan Hacking (2001) usefully calls valid arguments “risk-free arguments”.\nSome arguments may appear intuitively compelling to us, while they are not, in fact, valid. We say that they invalid. Consider the following:\n\nArgument (2)\nPremise 1: If Trillian is hungry, then she starts eating.\nPremise 2: Trillian starts eating.\nConclusion: Trillian is hungry.\n\nEven if the conclusion could happen to be true, it does not necessarily follow from the premises. Premise 1 does not rule out that Trillian could start eating even if not hungry. Thus, the fact that Trillian starts eating (Premise 2) does not necessarily imply that she is hungry. Trillian might simply be bored or trying to please a host who invited her for dinner, for instance.\nArgument (2) commits a fallacy, i.e., an error in reasoning. This particular fallacy is called “affirming the consequent”.\n\n\n2.2.2 Soundness\nWe have seen that a valid argument ensures that the conclusion is true if the premises are all true. But note that there is an important “if” there: if all the premises are true. In other words, an argument can be valid while its premises are false.\n\n\n\n\nTable 2.1: Determining the soundness of deductive arguments\n\n\n\nReasoning   ValidInvalidPremisesAll trueSoundUnsoundNot all trueUnsoundUnsound",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Elements of logic</span>"
    ]
  },
  {
    "objectID": "Logic.html#inductive-logic",
    "href": "Logic.html#inductive-logic",
    "title": "2  Elements of logic",
    "section": "2.3 Inductive logic",
    "text": "2.3 Inductive logic",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Elements of logic</span>"
    ]
  },
  {
    "objectID": "Logic.html#elements-of-set-theory",
    "href": "Logic.html#elements-of-set-theory",
    "title": "2  Elements of logic",
    "section": "2.4 Elements of set theory",
    "text": "2.4 Elements of set theory\nArguments using quantifiers like “all”, “some”, or “none” can usefully be represented through relations between sets.\n\n\n\n\n\n\n\nArgument (3)\nPremise 1: All scientists love statistics\nPremise 2: All social scientists are scientists\nConclusion: All social scientists love statistics\n\n\n\n\n\n\n\n\n\n\nFigure 2.1: Set representation of Argument (3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.2: An example of sets\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbol\n\n\n\n\n\\[\\Omega\\]\n\n\n\\[\\emptyset\\]\n\n\n\\[\\cup\\]\n\n\n\\[\\cap\\]\n\n\n\\[\\setminus\\]\n\n\n\\[\\tilde{}\\]\n\n\n\n\n\n\n\n\n\n\n\nHacking, I. (2001). An Introduction to Probability and Inductive Logic Desk Examination Edition. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Elements of logic</span>"
    ]
  },
  {
    "objectID": "Probability.html",
    "href": "Probability.html",
    "title": "3  Elements of probability theory",
    "section": "",
    "text": "3.1 What is probability?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability theory</span>"
    ]
  },
  {
    "objectID": "Probability.html#what-is-probability",
    "href": "Probability.html#what-is-probability",
    "title": "3  Elements of probability theory",
    "section": "",
    "text": "3.1.1 Two senses of the term “probability”\nConsider the two following statements\n\nStatement (1)\nThere is 0.95 probability that\n\n\nStatement (2)\nThere is 0.5 probability that flipping a fair coin will give me “heads”\n\n\n\n3.1.2 The classical definition\n\n\n\nClassical definition of probability  \\[\nP(A) = \\frac{\\#_A}{\\#_{total}}\n\\] The probability of A is the ratio between the number of favourable cases to the total number of cases.\n\n\nFigure 3.1\n\n\n\n\n\n3.1.3 The frequentist definition\nFormulated by John Venn (1888)\n\n\n\nFrequentist definition of probability  \\[\nP(A) = \\lim_{n\\to\\infty} \\frac{n_A}{n}\n\\] The probability of A is the limit of the relative frequency of A as the number of trials goes to infinity.\n\n\nFigure 3.2\n\n\n\n\n\n3.1.4 Kolmogorov’s axioms",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability theory</span>"
    ]
  },
  {
    "objectID": "Probability.html#the-calculus-of-probabilities",
    "href": "Probability.html#the-calculus-of-probabilities",
    "title": "3  Elements of probability theory",
    "section": "3.2 The calculus of probabilities",
    "text": "3.2 The calculus of probabilities\n\n3.2.1 The complement\n\n\n3.2.2 \n\n\n\n\nVenn, J. (1888). The Logic of Chance (3rd ed.). https://www.gutenberg.org/ebooks/57359",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability theory</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Diener, E., Wirtz, D., Tov, W., Kim-Prieto, C., Choi, D., Oishi, S.,\n& Biswas-Diener, R. (2010). New Well-being Measures: Short Scales to\nAssess Flourishing and Positive and Negative Feelings. Social\nIndicators Research, 97(2), 143–156. https://doi.org/10.1007/s11205-009-9493-y\n\n\nHacking, I. (2001). An Introduction to Probability and Inductive\nLogic Desk Examination Edition. Cambridge University Press.\n\n\nPopper, K. R. (2020). The Open Society and Its Enemies.\nPrinceton University Press.\n\n\nVenn, J. (1888). The Logic of Chance (3rd ed.). https://www.gutenberg.org/ebooks/57359\n\n\nWeziak-Bialowolska, D., Bialowolski, P., Lee, M. T., Chen, Y.,\nVanderWeele, T. J., & McNeely, E. (2021). Psychometric properties of\nflourishing scales from a comprehensive well-being assessment.\nFrontiers in Psychology, 12. https://doi.org/10.3389/fpsyg.2021.652209",
    "crumbs": [
      "References"
    ]
  }
]